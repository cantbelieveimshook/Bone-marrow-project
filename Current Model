import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw 
from numpy import asarray
from google.colab import drive
import torch
from torch import nn
from torch.utils.data import Dataset
import torchvision
import torchvision.transforms as transforms
import torch.nn.functional as F
from math import sqrt
import sklearn
from sklearn import cluster
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import tensorflow as tf 
from tensorflow import keras
from keras import layers
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, ReLU
from tensorflow.keras.layers import BatchNormalization, Conv2DTranspose, Concatenate
from tensorflow.keras.models import Model, Sequential
import os
from os import listdir
import torch.optim as optim

# loading all image paths into list
# can be used for any any amount of nested folders (hopefully, as long as it works properly)

mainfolder = '/content/drive/Shareddrives/Bone Marrow Classification'
labels = ['ABE', 'ART', 'BLA', 'EBO', 'EOS', 'FGC', 'HAC', 'KSC', 'LYI', 'LYT', 'MMZ', 'MON', 'MYB', 'NGB', 'NGS', 'NIF', 'OTH', 'PEB', 'PLM', 'PMO']

# loads all image paths from any folder, works with any combination of folders/degrees of nested folders
# currently modified to only add the first five image paths from each folder
# labels are currently unfortunately hardcoded because idk how else to get the labels from the images
def loadimagepaths(folder, images = []):
  i = 0
  for data in os.listdir(folder):
    subfolder = folder + '/' + data
    if (folder + '/.ipynb_checkpoints') in os.listdir(folder):
      os.listdir(folder).remove(folder + '/.ipynb_checkpoints')
    if data[-4:] == '.jpg':
      images.append(subfolder)
      label = subfolder[55:58]
      i += 1
    else: 
      loadimagepaths(subfolder, images)
    if i >= 10:
      break
  return images

all_image_paths = loadimagepaths('/content/drive/Shareddrives/Bone Marrow Classification')

# writing image paths and labels onto csv file
f = open('./dataset_info.csv', 'a')
f.write("Path, Label\n")

for path in all_image_paths:
  label = path[55:58]
  f.write(path + ',' + label + '\n')

f.close()

class BoneMarrowDataset(Dataset):
  def __init__(self, dataset_info_path):
    self.dataset_info_path = dataset_info_path
    self.df = pd.read_csv(self.dataset_info_path)
  def __len__(self):
    return self.df.shape[0]
  def __getitem__(self, idx):
    return torch.from_numpy(plt.imread(self.df.iloc[idx, 0]).transpose(2, 0, 1).reshape(1, 3, 250, 250)/255), self.df.iloc[idx, 1]

dataset=BoneMarrowDataset('dataset_info.csv')

train, test = train_test_split(dataset, test_size = 0.1, random_state = 1)

# taken from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial and modified a bit so it would work
class conv_block(nn.Module):
    def __init__(self, in_layers, out_layers):
        super().__init__()
        self.conv1 = nn.Conv2d(in_layers, out_layers, 3, padding = 1) # modified, was originally 3, 6, 5. shrunk kernel size from 5 to 3.
        self.bn1 = nn.BatchNorm2d(out_layers)
        self.conv2 = nn.Conv2d(out_layers, out_layers, 3, padding = 1)
        self.bn2 = nn.BatchNorm2d(out_layers)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.relu(self.bn2(self.conv2(x)))
        return x


class encoder(nn.Module):
  def __init__(self, in_layers, out_layers):
    super().__init__()
    self.conv = conv_block(in_layers, out_layers)
    self.pool = nn.MaxPool2d((2, 2))
  
  def forward(self, inputs):
    x = self.conv(inputs)
    pool = self.pool(x)
    return x, pool

class decoder(nn.Module):
    def __init__(self, in_layers, out_layers):
        super().__init__()
        self.up = nn.ConvTranspose2d(in_layers, out_layers, kernel_size = 2, stride = 2, padding = 0)
        self.conv = conv_block(out_layers + out_layers, out_layers)
    
    def forward(self, inputs, skip):
        x = self.up(inputs)
        print(np.shape(x))
        x = torch.cat([x, skip], axis = 1)
        x = self.conv(x)
        return x

class Net(nn.Module):
  def __init__(self):
    super().__init__()
    self.e1 = encoder(3, 64)
    self.e2 = encoder(64, 128)
    self.e3 = encoder(128, 256)
    self.e4 = encoder(256, 512)
    
    self.b = conv_block(512, 1024)
    
    self.d1 = decoder(1024, 512)
    self.d2 = decoder(512, 256)
    self.d3 = decoder(256, 128)
    self.d4 = decoder(128, 64)
    
    self.outputs = nn.Conv2d(64, 1, kernel_size = 1, padding = 0)

  def forward(self, inputs):
    s1, p1 = self.e1(inputs)
    s2, p2 = self.e2(p1)
    s3, p3 = self.e3(p2)
    s4, p4 = self.e4(p3)
    
    b = self.b(p4)

    d1 = self.d1(b, s4)
    d2 = self.d2(d1, s3)
    d3 = self.d3(d2, s2)
    d4 = self.d4(d3, s1)

    outputs = self.outputs(d4)

    return outputs


net = Net()

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
labels = ['ABE', 'ART', 'BLA', 'EBO', 'FGC', 'EOS', 'HAC', 'KSC', 'LYI', 'LYT', 'NGS', 'NGB', 'NIF', 'MYB', 'MON', 'MMZ', 'PEB', 'PLM', 'PMO', 'OTH']
le = preprocessing.LabelEncoder()
encoder = preprocessing.OneHotEncoder()
labels = le.fit(labels)
# encoder.fit(labels.reshape(-1, 1))
# labels = encoder.transform(labels.reshape(-1, 1))

for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(train, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, label = data
        inputs = inputs.float()
        label = le.transform([label])
        encoder.fit(label.reshape(-1, 1))
        label = encoder.transform(label.reshape(-1, 1))

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, torch.as_tensor(label))
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 100 == 1:    # print every 100 mini-batches
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')
            running_loss = 0.0

print('B)')

correct = 0
total = 0
# since we're not training, we don't need to calculate the gradients for our outputs
with torch.no_grad():
    for data in test:
        inputs, label = data
        inputs = inputs.float()
        label = torch.as_tensor(le.transform([label]))
        # calculate outputs by running images through the network
        outputs = net(inputs)
        # the class with the highest energy is what we choose as prediction
        _, predicted = torch.max(outputs.data, 1)
        total += label.size(0)
        correct += (predicted == label).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')

# prepare to count predictions for each class
correct_pred = {classname: 0 for classname in labels}
total_pred = {classname: 0 for classname in labels}

# again no gradients needed
with torch.no_grad():
    for data in test:
        inputs, classifications = data
        inputs = inputs.float()
        classifications = torch.as_tensor(le.transform([classifications]))
        outputs = net(inputs)
        _, predictions = torch.max(outputs, 1)
        # collect the correct predictions for each class
        for label, prediction in zip(classifications, predictions):
            if label == prediction:
                correct_pred[labels[label]] += 1
            total_pred[labels[label]] += 1

# print accuracy for each class
for classname, correct_count in correct_pred.items():
  if total_pred[classname] != 0:
    accuracy = 100 * float(correct_count) / total_pred[classname]
    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')
  else:
    print(f'No predictions for this class: {classname}')

